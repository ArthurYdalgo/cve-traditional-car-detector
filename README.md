# Vehicle Detector

Traditional implementation to detect cars that pass through a designated area

# Step-by-step installation

Make sure pip is installed
    
    $ sudo apt install python3-pip

### Clone the repo or download it as a .zip file, and then unzip it
    $ git clone https://github.com/ArthurYdalgo/cve-traditional-car-detector

### Once inside the repo folder
    $ sudo chmod +x setup.sh
    $ ./setup.sh

### Execute
    $ ./main.py

Alternatively, the EntityDetector can be used as desired by importing the entityDetector, declaring a EntityDetector and running the 'detect()' method

    $ import entityDetector as ed
    $ entity_detector = ed.EntityDetector()
    $ entity_detector.detect()


# Changing parameters
## Footage source
The source is, as default, the 'road footage.mp4' file. In case a different source is desired, add a 'footage_source' paramenter in the EntityDetector declaration in 'main.py'

    $ entity_detector = ed.EntityDetector(footage_source='another footage.mp4')

or send an integer if the source is a connected device. To use your webcam, use 0 as paramenter

    $ entity_detector = ed.EntityDetector(footage_source=0)

## Thresholds, minimum ratios, tolerance and footage fps
The following parameter can be overwritten in the EntityDetector initializer

    $ entity_detector = ed.EntityDetector(footage_fps = 1/15, minimum_area_ratio = 0.35, center_displacement_tolerance = 0.6)

Parameters:
- footage_fps: sets the footage's refresh rate (which is 15fps by default)
- minimum_area_ratio: in order to a detection to be validated, it needs a minimum area ratio (detection_rate by the search area, which is 0.35 (35 %) by default)
- center_displacement_tolerance: in order to a detection be validated, it's center needs to be within a defined tolerance (which is by default 0.6 (60 %))


## Search area
The middle lane (from the footage camera's perspective, starting from the left) is the default search area. In case a new area is desired, add a 'search_area' parameter in the EntityDetector declaration in 'main.py', which is a dictionary containing the x and y center of the search area, and it's dimensions (width and height)

    $ x, y, width, height = 715, 475, 150, 35
    $ desired_area = {'position': (x, y), 'dimension': (width, height)}
    $ entity_detector = ed.EntityDetector(search_area = desired_area)

## Detailed detection
![](readme_images/detection_gif.gif)

By default, the footage source is displayed and the output (if there's any) is printed in the console (the result is also displayed in the footage). In case any of them is not desired, simply add the parameters when the 'detect()' method is called. Be aware that in case the console output is keept enabled, an output will be printed for every frame that contains a valid detection. There's also a detailed detection (deactivated by default), which displays every step of the detection algorithm. To enable it, add 'detailed_detection' in the 'detect()' method

    $ enity_detector.detect(console_output = False, detailed_detection = True)

Footage display can be entirely deactivated by setting the 'detect()' display parameter to False

    $ enity_detector.detect(display = False)



